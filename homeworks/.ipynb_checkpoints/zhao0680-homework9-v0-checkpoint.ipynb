{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\\begin{equation*}\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\Nor}{\\mathcal{N}}\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "# Due Dates\n",
    "\n",
    "* Theoretical Problems: Tuesday, November 27, in class \n",
    "* Coding: Due to the shortened week, there will be no coding problems. However,\n",
    "the concepts from class will be demonstrated in code below.\n",
    "\n",
    "\n",
    "# Theoretical Problems\n",
    "\n",
    "Those diligent students that came to class know that Andy did an atrocious job of presenting\n",
    "the ensemble Kalman filter. (Section 4.7 in the text.) While it is mostly Andy's fault, \n",
    "the book has several crucial inaccuracies. First we will describe the corrected equations and\n",
    "the theoretical assignment will be to justify the corrections.\n",
    "\n",
    "\n",
    " $$\\begin{aligned}x_{k+1} = f(x_k,u_k,w_k), \\quad w_k \\sim\\mathcal{N}(0,Q) \\\\y_k =h(x_k,v_k),\\quad v_k \\sim\\mathcal{N}(0,R) \\end{aligned}$$\n",
    " \n",
    "We will assume that $x_0\\sim\\mathcal{N}(x_0^-,P_0^-)$\n",
    " \n",
    "The ensemble Kalman filter using $N$ particles is given as follows:\n",
    "\n",
    "Initialize particle $i$ by randomly drawing:\n",
    "$$ x_0^{-(0)} \\sim \\mathcal{N}(\\hat x_0^-,P_0^-)$$\n",
    "\n",
    "For time step $k\\ge 0$, do the following:\n",
    "\n",
    "Generate particle measurements:\n",
    "$$y_k^{-(j)} = h( x_k^{-(j)},v_k^{(j)}), \\quad v_k^{(j)}\\sim \\mathcal{N}(0,R)$$\n",
    "\n",
    "Estimate the prior means:\n",
    "\\begin{align*}\n",
    "\\bar x_k &= \\frac{1}{N} \\sum_{j=1}^N  x_k^{-(j)}\\\\\n",
    "\\bar y_k &= \\frac{1}{N} \\sum_{j=1}^N y_k^{-(j)}\n",
    "\\end{align*}\n",
    "\n",
    "Estimate the covariance matrices and gain:\n",
    "\\begin{align*}\n",
    "P_k^{xy} &= \\frac{1}{N} \\sum_{j=1}^N (x_k^{-(j)} - \\bar x_k)(y_k^{-(j)} - \\bar y_k)^\\top \n",
    "\\\\\n",
    "P_k^{yy} &= \\frac{1}{N} \\sum_{j=1}^N (y_k^{-(j)} - \\bar y_k)(y_k^{-(j)} - \\bar y_k)^\\top \n",
    "\\\\\n",
    "K_k &= P_k^{xy} (P_k^{yy})^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "Measurement update:\n",
    "$$\n",
    "x_k^{+(j)} = x_k^{-(j)}+K_k(y_k - y_k^{-(j)})\n",
    "$$\n",
    "\n",
    "Time Update:\n",
    "$$\n",
    "x_{k+1}^{-(j)} = f(x_k^{+(j)},u_k,w_k^{(j)}), \\quad w_k^{(j)} \\sim \\mathcal{N}(0,Q)\n",
    "$$\n",
    "\n",
    "The primary difference between this algorithm and the method from the book is that here the measurement noise appears in the particle measurements, $y_k^{-(j)}$. This, in turn, changes the calculation for $P_k^{yy}$. As we will see this correction leads to the desired covariance matrix.\n",
    "\n",
    "A minor difference is that we normalized by $N$ everywhere. The book normalizes by $N-1$ everywhere. This leads to biased estimates for the mean terms. For the covariance terms, the normalization does not actually matter since the normalizing constants cancel when computing $K_k$. However, for large $N$, the differences in the normalizing factors will not change much. \n",
    "\n",
    "To theoretically justify the algorithm, we will assume that the system is linear, so that\n",
    "\\begin{align*}\n",
    "x_{k+1} &= \\Phi x_k + \\Gamma u_k + w_k \\\\\n",
    "y_k &= H x_k + v_k\n",
    "\\end{align*}\n",
    "Also, for simplicity, assume that $u_k$ is deterministic. \n",
    "\n",
    "\n",
    "Let $\\hat x_k^- = \\E[x_k | y_{0:k-1}]$ and $P_k^- = \\E[(x_k-\\hat x_k^-)(x_k-\\hat x_k^-)^\\top ]$ \n",
    "and let $\\hat x_k^+ = \\E[x_k|y_{0:k}]$ and $P_k = \\E[(x_k-\\hat x_k^+)(x_k-\\hat x_k^+)^\\top]$.\n",
    "\n",
    "We will show the following things as $N\\to\\infty$:\n",
    "* $x_k^{-(j)}\\sim \\Nor(\\hat x_k^-,P_k^-)$\n",
    "* $x_k^{+(j)}\\sim \\Nor(\\hat x_k^+,P_k^+)$\n",
    "* $K_k \\to P^-_kH^\\top (HP_k^-H^\\top +R)^{-1}$.\n",
    "* $\\bar x_k \\to \\hat x_k^-$.\n",
    "\n",
    "In other words, the particles are actually samples from the filtering density. \n",
    "\n",
    "# Theoretical Question 0\n",
    "\n",
    "Assume that the conditional density of $x_k^{-(j)}$ is given by $p(x_k^{-(j)}|y_{0:k-1}) = \\Nor(x_k^{-(j)}|\\hat x_k^-,P_k^-)$.\n",
    "\n",
    "Show that $\\E[(x_k^{-(j)}-\\hat x_k^-)(y_k^{-(j)}-H \\hat x_k^-)^\\top] = P_k^- H^\\top$\n",
    "and $\\E[(y_k^{-(j)}-H\\hat x_k^-)(y_k^{-(j)}-H \\hat x_k^-)^\\top] = H P_k^- H^\\top + R$.\n",
    "\n",
    "If you can show those equalities, then for large $N$, the law of large numbers implies that \n",
    "the estimates for the covariance matrices are nearly exact, and thus the estimated gain is nearly optimal.\n",
    "\n",
    "# Theoretical Question 1\n",
    "\n",
    "\n",
    "Assume that $p(x_k^{-(j)}|y_{0:k-1}) = \\Nor(x_k^{-(j)}|\\hat x_k^-,P_k^-)$ and assume that $K_k = P_k^- H^\\top (H P_k^- H^\\top +R)^{-1}$. In other words, we are assuming that the gain is optimal.\n",
    "\n",
    "Show that $\\E[x_k^{+(j)}|y_{0:k}] = \\hat x_k^+$ and $\\E[(x_k^{+(j)}-\\hat x_k^+)(x_k^{+(j)}-\\hat x_k^+)^\\top | y_{0:k}] = P_k^+$.\n",
    "\n",
    "If you can show these equalities, it follows that $p(x_k^{+(j)}|y_{0:k})=\\Nor(x_k^{+(j)}|\\hat x_k^+,P_k^+)$.\n",
    "\n",
    "# Theoretical Question 2\n",
    "\n",
    "Assume that $p(x_k^{+(j)}|y_{0:k})=\\Nor(x_k^{+(j)}|\\hat x_k^+,P_k^+)$. \n",
    "\n",
    "Show that $\\E[x_{k+1}^{-(j)}|y_{0:k}] = \\hat x_{k+1}^-$ and \n",
    "$\\E[(x_{k+1}^{-(j)}-\\hat x_{k+1}^-)(x_{k+1}^{-(j)}-\\hat x_{k+1}^-)^\\top|y_{0:k}] = P_{k+1}^-$.\n",
    "\n",
    "If you can show these equalities, it follows that $p(x_{k+1}^{-(j)}|y_{0:k})=\\Nor(x_{k+1}^{-(j)}|\\hat x_{k+1}^-,P_{k+1}^-)$.\n",
    "\n",
    "Combining all of the results from the theoretical questions shows that the particles sample from \n",
    "the filtering density, by induction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True', evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# This is code to load the assignment.\n",
    "# You'll need to run this code do or restart the assignment.\n",
    "from loadAssignment import loadAssignment\n",
    "Assignment, Questions, Submit, Data = loadAssignment(9)\n",
    "\n",
    "# These are modules that we need\n",
    "# once you run this code, you don't need to load them again\n",
    "import autograd.numpy as np\n",
    "import autograd as ag\n",
    "import scipy.linalg as la\n",
    "import scipy.signal as sp\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "Here is some code that may be helpful. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True'\t,evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def dot(*mats):\n",
    "    \"\"\"\n",
    "    Computes product of arbitrary matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(mats) == 1:\n",
    "        return mats[0]\n",
    "    else:\n",
    "        return np.dot(mats[0],dot(*mats[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Question 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": " echo='True' ,evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def dot(*mats):\n",
    "    \"\"\"\n",
    "    Computes product of arbitrary matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(mats) == 1:\n",
    "        return mats[0]\n",
    "    else:\n",
    "        return np.dot(mats[0],dot(*mats[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "# Gaussian Sum Filter Example\n",
    "\n",
    "Here is a simple example of the Gaussian sum filter applied to \n",
    "\n",
    "\\begin{align*}\n",
    " x_{k+1} &= x_k + u_k + .1 * w_k \\\\\n",
    " y_k &= |x_k| + .5 (|x_k| + .1) v_k\n",
    "\\end{align*}\n",
    "\n",
    "We assume a density of the form $p(x_k|y_{0:k}) = \\sum_{i=1}^N w_k^{(i)}\\Nor(x_k |\\hat x_k^{+(i)},P_k^{+(i)})$.\n",
    "\n",
    "The plots show how the density evolves as more data is collected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True',evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def dot(*mats):\n",
    "    \"\"\"\n",
    "    Computes product of arbitrary matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(mats) == 1:\n",
    "        return mats[0]\n",
    "    else:\n",
    "        return np.dot(mats[0],dot(*mats[1:]))\n",
    "\n",
    "def step(x,u,w):\n",
    "    return x + u + .1 * w\n",
    "\n",
    "def measure(x,v):\n",
    "    return np.abs(x) + .5 * (np.abs(x) + .1) * v\n",
    "\n",
    "\n",
    "dfdx = ag.jacobian(step,argnum=0)\n",
    "dfdw = ag.jacobian(step,argnum=2)\n",
    "\n",
    "dhdx = ag.jacobian(measure,argnum=0)\n",
    "dhdv = ag.jacobian(measure,argnum=1)\n",
    "\n",
    "NumModes = 6\n",
    "n = 1\n",
    "\n",
    "var0 = 5.\n",
    "mu_list = np.linspace(-10,10,NumModes).reshape((NumModes,n))\n",
    "P_list = np.array([var0 * np.eye(n) for _ in range(NumModes)])\n",
    "Weights = np.ones(NumModes) / NumModes\n",
    "\n",
    "def mixturePdf(x,mu_list,P_list,Weights):\n",
    "    pdf = np.zeros_like(x)\n",
    "    for mu,P,w in zip(mu_list,P_list,Weights):\n",
    "        pdf += w * st.norm.pdf(x,loc=mu[0],scale=np.sqrt(P[0,0]))\n",
    "        \n",
    "    return pdf\n",
    "\n",
    "def mixtureRvs(mu_list,P_list,Weights):\n",
    "    ind = rnd.choice(np.arange(len(Weights)),p=Weights)\n",
    "    mu = mu_list[ind]\n",
    "    P = P_list[ind]\n",
    "    \n",
    "    CP = la.cholesky(P,lower=True)\n",
    "    \n",
    "    n = len(mu)\n",
    "    return np.dot(CP,rnd.randn(n)) + mu\n",
    "    \n",
    "\n",
    "NumSteps = 8\n",
    "\n",
    "fig,ax = plt.subplots(int(NumSteps/2),2,sharex=True)\n",
    "\n",
    "\n",
    "\n",
    "W = rnd.randn(NumSteps,n)\n",
    "V = rnd.randn(NumSteps,n)\n",
    "\n",
    "x = np.array([-4])\n",
    "\n",
    "U = 1 * np.ones((NumSteps,n))\n",
    "\n",
    "x_plot = np.linspace(-15,15,200)\n",
    "\n",
    "for k in range(NumSteps):\n",
    "    w = W[k]\n",
    "    v = V[k]\n",
    "    u = U[k]\n",
    "    \n",
    "    # Update\n",
    "    y = measure(x,v)\n",
    "    \n",
    "    Weights_pre = np.zeros_like(Weights)\n",
    "    \n",
    "    for i in range(NumModes):\n",
    "        mu = mu_list[i]\n",
    "        P = P_list[i]\n",
    "        H = dhdx(mu,np.zeros(n))\n",
    "        J = dhdv(mu,np.zeros(n))\n",
    "        Psi = dot(H,P,H.T) + np.dot(J,J.T)\n",
    "        \n",
    "        y_guess = measure(mu,np.zeros(n))\n",
    "        likelihood = st.multivariate_normal.pdf(y,mean=y_guess,cov=Psi)\n",
    "        Weights_pre[i] = Weights[i] * likelihood\n",
    "        \n",
    "        K = la.solve(Psi,np.dot(H,P)).T\n",
    "        mu_list[i] = mu + np.dot(K,y-y_guess)\n",
    "        P_list[i] = P - dot(K,Psi,K.T)\n",
    "        \n",
    "    Weights = Weights_pre / np.sum(Weights_pre)\n",
    "    pdf_plot = mixturePdf(x_plot,mu_list,P_list,Weights)\n",
    "    ax[k % int(NumSteps/2),int( 2 * k/NumSteps)].plot(x_plot,pdf_plot)\n",
    "    ax[k % int(NumSteps/2),int(2 * k/NumSteps)].plot(x[0],0,'*')\n",
    "    ax[k % int(NumSteps/2),int(2 * k/NumSteps)].set_title('Step %d' % k)\n",
    "    \n",
    "    for i in range(NumModes):\n",
    "        mu_post = mu_list[i]\n",
    "        P_post = P_list[i]\n",
    "        # Prediction\n",
    "        F = dfdx(mu_post,u,np.zeros(n))\n",
    "        G = dfdw(mu_post,u,np.zeros(n))\n",
    "        \n",
    "        mu_list[i] = step(mu_post,u,np.zeros(n))\n",
    "        P_list[i] = np.dot(G,G.T) + dot(F,P_post,F.T)\n",
    "        \n",
    "        \n",
    "     \n",
    "    x = step(x,u,w)\n",
    "        \n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "# Ensemble Kalman Filter Example\n",
    "\n",
    "Below we will similulate a system of coupled nonlinear oscillators.\n",
    "\n",
    "Here the system has $100$ oscillators, arranged on a $10\\times 10$ lattice. Since each oscillator\n",
    "is a second-order system, the state dimension is $200$. \n",
    "\n",
    "We will assume that $10$ of the oscillators (chosen at random) are measured. We will construct\n",
    "an estimate of the full state using the ensemble Kalman filter.\n",
    "\n",
    "The first bit of code here is just the simulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": " echo='True',evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "AllIndices = np.arange(n**2)\n",
    "\n",
    "Neighbors = {i : [] for i in AllIndices }\n",
    "\n",
    "\n",
    "for i in AllIndices:\n",
    "    ri,ci = np.unravel_index(indices=i,dims=(n,n))\n",
    "    for j in AllIndices:\n",
    "        rj,cj = np.unravel_index(indices=j,dims=(n,n))\n",
    "        \n",
    "        if (np.abs(ri-rj) + np.abs(ci-cj) == 1) and (i < j):\n",
    "            Neighbors[i].append(j)\n",
    "            Neighbors[j].append(i)\n",
    "\n",
    "NumSteps = 500\n",
    "Time = np.linspace(0,20,NumSteps)\n",
    "dt = Time[1] - Time[0]\n",
    "\n",
    "def oscillatorStep(x,u,w):\n",
    "    sig_w = .001\n",
    "    zeta = .1\n",
    "    omega_nat = 1.\n",
    "    K_spring = omega_nat**2\n",
    "    K_damping = 2 * zeta * omega_nat \n",
    "    N = int(len(x)/2)\n",
    "    n = int(np.round(np.sqrt(N)))\n",
    "    q = x[:N]\n",
    "    dq = x[N:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    q_dot = np.copy(dq)\n",
    "    dq_dot = -K_damping * dq + omega_nat**2 * sig_w * w/np.sqrt(dt)\n",
    "    for i in range(N):\n",
    "        dq_dot[i] -=  K_spring * np.sum(np.sin(q[i] - q[Neighbors[i]] ))\n",
    "    \n",
    "    inputInd = np.ravel_multi_index(multi_index=(int(n/2),int(n/2)),dims=(n,n))\n",
    "    \n",
    "    dq_dot[inputInd] += omega_nat**2 * u[0]\n",
    "    \n",
    "    return x + dt * np.hstack([q_dot,dq_dot])\n",
    "\n",
    "NumSensors = n\n",
    "\n",
    "SensorIndices = rnd.permutation(np.arange(n**2))[:n]\n",
    "\n",
    "def measureOscillator(x,v):\n",
    "    return x[SensorIndices] + .01 * v\n",
    "\n",
    "sig_x = .01\n",
    "x = sig_x * rnd.randn(2*n**2)\n",
    "\n",
    "X = []\n",
    "\n",
    "\n",
    "U = 2 * np.sin(.2 * Time).reshape((len(Time),1))\n",
    "\n",
    "for k in range(NumSteps):\n",
    "    X.append(x)\n",
    "    u =U[k]\n",
    "    x = oscillatorStep(x,u,rnd.randn(n**2))\n",
    "\n",
    "X =np.array(X)\n",
    "\n",
    "Y = np.array([measureOscillator(x,v) for x,v in zip(X,rnd.randn(len(X),NumSensors))])\n",
    "    \n",
    "    \n",
    "plt.plot(Time,X)\n",
    "plt.title('States')\n",
    "plt.figure()\n",
    "plt.plot(Time,Y)\n",
    "plt.title('Measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "The next bit is the actual ensemble Kalman filter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True',evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "NumParticles = 20\n",
    "\n",
    "X_ens = []\n",
    "\n",
    "for _ in range(NumParticles):\n",
    "    x = sig_x * rnd.randn(2*n**2)\n",
    "    X_ens.append(x)\n",
    "    \n",
    "    \n",
    "X_ens = np.array(X_ens)\n",
    "\n",
    "X_est = np.zeros((NumSteps,2*n**2))\n",
    "for k in range(NumSteps):\n",
    "    # Particle measuremnts\n",
    "    Y_ens = np.array([measureOscillator(x,rnd.randn(NumSensors)) for x in X_ens])\n",
    "    \n",
    "    # Prior Means\n",
    "    x_pre = np.mean(X_ens,axis=0)\n",
    "    y_pre = np.mean(Y_ens,axis=0)\n",
    "    \n",
    "    # Just using the prior estimate for simplicity\n",
    "    # This corresponds to \\bar{x}_k\n",
    "    X_est[k] = x_pre\n",
    "        \n",
    "    # Covariance Matrices\n",
    "    Pxy = np.zeros((len(x),NumSensors))\n",
    "    Pyy = np.zeros((NumSensors,NumSensors))\n",
    "    \n",
    "    for x,y in zip(X_ens,Y_ens):\n",
    "        res_x = x - x_pre\n",
    "        res_y = y - y_pre\n",
    "        \n",
    "        Pxy += np.outer(res_x,res_y) /(NumParticles-1)\n",
    "        Pyy += np.outer(res_y,res_y) / (NumParticles-1)\n",
    "        \n",
    "    # Gain    \n",
    "    K = la.solve(Pyy,Pxy.T).T\n",
    "    \n",
    "    for i in range(NumParticles):\n",
    "        x = X_ens[i]\n",
    "        y = Y_ens[i]\n",
    "        # Measurement Update\n",
    "        x = x + np.dot(K,Y[k]-y)\n",
    "        # Time Update\n",
    "        x = oscillatorStep(x,U[k],rnd.randn(n**2))\n",
    "        X_ens[i] = x\n",
    "        \n",
    "plt.plot(Time,X_est)\n",
    "plt.title('State Estimates')\n",
    "plt.figure()\n",
    "plt.plot(Time,X_est - X)\n",
    "plt.title('Estimation Errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "# Final Score\n",
    "\n",
    "You can run this code to see all of your scores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True', evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "Assignment.showResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Submission\n",
    "\n",
    "Save your work and run this cell to submit. It will only work if you have the internet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "echo='True', evaluate='False' ",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "Submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "estenv"
  },
  "kernelspec": {
   "display_name": "Estimation",
   "language": "python",
   "name": "estenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
